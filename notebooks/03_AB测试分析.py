# -*- coding: utf-8 -*-
"""
03_ABæµ‹è¯•åˆ†æ.py
A/Bæµ‹è¯•è®¾è®¡ä¸åˆ†æï¼ŒåŒ…å«å®éªŒè®¾è®¡ã€ç»Ÿè®¡æ£€éªŒã€æ•ˆæœè¯„ä¼°ç­‰
ä½¿ç”¨ #%% åˆ†éš”ä»£ç å—ï¼Œæ¨¡æ‹Ÿ Jupyter Notebook
"""

#%% å¯¼å…¥å¿…è¦çš„åº“
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import norm, ttest_ind, chi2_contingency
import sys
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))
from analysis import EcommerceAnalyzer
from visualization import EcommerceVisualizer

# è®¾ç½®æ ·å¼
plt.style.use('seaborn-v0_8')
sns.set_palette("Set2")

print("ğŸ§ª A/Bæµ‹è¯•è®¾è®¡ä¸åˆ†æ")
print("=" * 50)

#%% åˆå§‹åŒ–å’Œæ•°æ®å‡†å¤‡
print("\nğŸ”§ åˆå§‹åŒ–åˆ†æå·¥å…·...")

# åˆ›å»ºåˆ†æå™¨å®ä¾‹
analyzer = EcommerceAnalyzer()
visualizer = EcommerceVisualizer()

# åŠ è½½æ•°æ®
analyzer.load_data()
print("âœ… æ•°æ®åŠ è½½å®Œæˆï¼")

# å‡†å¤‡æµ‹è¯•æ•°æ®
users_df = analyzer.users
orders_df = analyzer.orders
behaviors_df = analyzer.behaviors

print(f"æ•°æ®æ¦‚å†µ:")
print(f"- ç”¨æˆ·æ•°: {len(users_df):,}")
print(f"- è®¢å•æ•°: {len(orders_df):,}")
print(f"- è¡Œä¸ºè®°å½•: {len(behaviors_df):,}")

#%% A/Bæµ‹è¯•åœºæ™¯è®¾è®¡
print("\nğŸ“‹ A/Bæµ‹è¯•åœºæ™¯è®¾è®¡")
print("-" * 30)

print("ã€æµ‹è¯•åœºæ™¯ã€‘æ–°ç”¨æˆ·ä¼˜æƒ åˆ¸å¯¹è½¬åŒ–ç‡çš„å½±å“")
print("- æ§åˆ¶ç»„ (A): ä¸å‘æ”¾ä¼˜æƒ åˆ¸")
print("- å®éªŒç»„ (B): å‘æ”¾10å…ƒæ–°ç”¨æˆ·ä¼˜æƒ åˆ¸")
print("- ä¸»è¦æŒ‡æ ‡: è½¬åŒ–ç‡ã€å¹³å‡è®¢å•é‡‘é¢ã€ç”¨æˆ·ä»·å€¼")
print("- æ¬¡è¦æŒ‡æ ‡: å¤è´­ç‡ã€ç”¨æˆ·æ»¡æ„åº¦")

# æ¨¡æ‹ŸA/Bæµ‹è¯•åˆ†ç»„ï¼ˆåŸºäºç”¨æˆ·IDçš„éšæœºåˆ†ç»„ï¼‰
np.random.seed(42)
users_df_test = users_df.copy()

# ç­›é€‰æ–°ç”¨æˆ·ï¼ˆæ³¨å†Œæ—¶é—´åœ¨æœ€è¿‘30å¤©å†…ï¼‰
recent_date = users_df['register_date'].max()
cutoff_date = recent_date - pd.Timedelta(days=30)
new_users = users_df_test[users_df_test['register_date'] >= cutoff_date].copy()

if len(new_users) > 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ–°ç”¨æˆ·
    # éšæœºåˆ†ç»„
    new_users['test_group'] = np.random.choice(['A', 'B'], size=len(new_users), p=[0.5, 0.5])
    
    # ç»Ÿè®¡åˆ†ç»„æƒ…å†µ
    group_stats = new_users['test_group'].value_counts()
    print(f"\nã€åˆ†ç»„æƒ…å†µã€‘")
    print(f"æ§åˆ¶ç»„ (A): {group_stats.get('A', 0)} äºº")
    print(f"å®éªŒç»„ (B): {group_stats.get('B', 0)} äºº")
    print(f"æ€»è®¡: {len(new_users)} äºº")
    
    # æ£€æŸ¥åˆ†ç»„å¹³è¡¡æ€§
    print(f"\nã€åˆ†ç»„å¹³è¡¡æ€§æ£€æŸ¥ã€‘")
    balance_check = new_users.groupby('test_group').agg({
        'age': 'mean',
        'gender': lambda x: (x == 'M').mean(),
        'user_level': lambda x: (x == 'Gold').mean()
    })
    print("å„ç»„ç”¨æˆ·ç‰¹å¾å¯¹æ¯”:")
    print(f"å¹³å‡å¹´é¾„: Aç»„ {balance_check.loc['A', 'age']:.1f}å², Bç»„ {balance_check.loc['B', 'age']:.1f}å²")
    print(f"ç”·æ€§æ¯”ä¾‹: Aç»„ {balance_check.loc['A', 'gender']:.1%}, Bç»„ {balance_check.loc['B', 'gender']:.1%}")
    print(f"Goldç”¨æˆ·æ¯”ä¾‹: Aç»„ {balance_check.loc['A', 'user_level']:.1%}, Bç»„ {balance_check.loc['B', 'user_level']:.1%}")
    
    test_ready = True
else:
    print("âš ï¸ æ–°ç”¨æˆ·æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰ç”¨æˆ·è¿›è¡Œæ¨¡æ‹Ÿæµ‹è¯•")
    users_df_test['test_group'] = np.random.choice(['A', 'B'], size=len(users_df_test), p=[0.5, 0.5])
    new_users = users_df_test
    test_ready = True

#%% æ ·æœ¬é‡è®¡ç®—
print("\nğŸ“Š æ ·æœ¬é‡è®¡ç®—")
print("-" * 30)

def calculate_sample_size(baseline_rate, mde, alpha=0.05, power=0.8):
    """
    è®¡ç®—A/Bæµ‹è¯•æ‰€éœ€æ ·æœ¬é‡
    baseline_rate: åŸºçº¿è½¬åŒ–ç‡
    mde: æœ€å°å¯æ£€æµ‹æ•ˆåº” (Minimum Detectable Effect)
    alpha: æ˜¾è‘—æ€§æ°´å¹³
    power: ç»Ÿè®¡åŠŸæ•ˆ
    """
    # ä½¿ç”¨æ­£æ€åˆ†å¸ƒè¿‘ä¼¼
    z_alpha = norm.ppf(1 - alpha/2)
    z_beta = norm.ppf(power)
    
    p1 = baseline_rate
    p2 = baseline_rate * (1 + mde)
    
    # åˆå¹¶æ ‡å‡†å·®
    p_pooled = (p1 + p2) / 2
    
    # è®¡ç®—æ ·æœ¬é‡
    n = 2 * (z_alpha + z_beta)**2 * p_pooled * (1 - p_pooled) / (p1 - p2)**2
    
    return int(n)

# ä¼°ç®—åŸºçº¿è½¬åŒ–ç‡
if test_ready and len(orders_df) > 0:
    # è®¡ç®—å†å²è½¬åŒ–ç‡
    total_active_users = behaviors_df['user_id'].nunique()
    paying_users = orders_df['user_id'].nunique()
    baseline_conversion_rate = paying_users / total_active_users
    
    print(f"ã€å†å²åŸºçº¿æ•°æ®ã€‘")
    print(f"æ´»è·ƒç”¨æˆ·æ•°: {total_active_users:,}")
    print(f"ä»˜è´¹ç”¨æˆ·æ•°: {paying_users:,}")
    print(f"åŸºçº¿è½¬åŒ–ç‡: {baseline_conversion_rate:.2%}")
    
    # è®¡ç®—ä¸åŒæ•ˆåº”é‡ä¸‹çš„æ ·æœ¬é‡éœ€æ±‚
    print(f"\nã€æ ·æœ¬é‡è®¡ç®—ã€‘")
    effect_sizes = [0.05, 0.10, 0.15, 0.20]  # 5%, 10%, 15%, 20% ç›¸å¯¹æå‡
    
    for mde in effect_sizes:
        sample_size = calculate_sample_size(baseline_conversion_rate, mde)
        print(f"æ£€æµ‹ {mde:.0%} ç›¸å¯¹æå‡: æ¯ç»„éœ€è¦ {sample_size:,} ç”¨æˆ·")
    
    # æ ¹æ®å®é™…ç”¨æˆ·æ•°ç¡®å®šå¯æ£€æµ‹çš„æœ€å°æ•ˆåº”
    available_users_per_group = len(new_users) // 2
    print(f"\nå®é™…å¯ç”¨ç”¨æˆ·: æ¯ç»„ {available_users_per_group:,} äºº")
    
    # é€†å‘è®¡ç®—å¯æ£€æµ‹çš„æœ€å°æ•ˆåº”
    if available_users_per_group > 100:
        detectable_effects = []
        for mde in np.arange(0.01, 0.5, 0.01):
            required_size = calculate_sample_size(baseline_conversion_rate, mde)
            if required_size <= available_users_per_group:
                detectable_effects.append(mde)
        
        if detectable_effects:
            min_detectable = min(detectable_effects)
            print(f"å½“å‰æ ·æœ¬é‡å¯æ£€æµ‹æœ€å°æ•ˆåº”: {min_detectable:.1%}")
        else:
            print("âš ï¸ å½“å‰æ ·æœ¬é‡å¯èƒ½ä¸è¶³ä»¥æ£€æµ‹åˆ°æ˜¾è‘—æ•ˆåº”")

#%% æ¨¡æ‹Ÿå®éªŒæ•ˆæœ
print("\nğŸ² æ¨¡æ‹Ÿå®éªŒæ•ˆæœ")
print("-" * 30)

if test_ready:
    # æ¨¡æ‹Ÿä¼˜æƒ åˆ¸å¯¹è½¬åŒ–ç‡å’Œè®¢å•é‡‘é¢çš„å½±å“
    print("æ¨¡æ‹Ÿä¼˜æƒ åˆ¸æ•ˆæœ...")
    
    # è·å–æµ‹è¯•ç”¨æˆ·çš„è¡Œä¸ºå’Œè®¢å•æ•°æ®
    test_user_ids = new_users['user_id'].tolist()
    test_behaviors = behaviors_df[behaviors_df['user_id'].isin(test_user_ids)].copy()
    test_orders = orders_df[orders_df['user_id'].isin(test_user_ids)].copy()
    
    # åˆå¹¶åˆ†ç»„ä¿¡æ¯
    test_behaviors = test_behaviors.merge(
        new_users[['user_id', 'test_group']], on='user_id', how='left'
    )
    test_orders = test_orders.merge(
        new_users[['user_id', 'test_group']], on='user_id', how='left'
    )
    
    # æ¨¡æ‹ŸBç»„æ•ˆæœæå‡ï¼ˆä¼˜æƒ åˆ¸æ•ˆæœï¼‰
    # å‡è®¾ä¼˜æƒ åˆ¸ä½¿è½¬åŒ–ç‡æå‡15%ï¼Œå¹³å‡è®¢å•é‡‘é¢æå‡8%
    conversion_lift = 0.15  # è½¬åŒ–ç‡æå‡15%
    aov_lift = 0.08        # å¹³å‡è®¢å•é‡‘é¢æå‡8%
    
    # ä¸ºBç»„ç”¨æˆ·å¢åŠ é¢å¤–çš„è½¬åŒ–è¡Œä¸ºï¼ˆæ¨¡æ‹Ÿä¼˜æƒ åˆ¸æ•ˆæœï¼‰
    group_b_users = new_users[new_users['test_group'] == 'B']['user_id'].tolist()
    
    # æ¨¡æ‹ŸBç»„é¢å¤–çš„æ”¯ä»˜è¡Œä¸º
    additional_conversions = []
    for user_id in group_b_users:
        if np.random.random() < conversion_lift:  # 15%çš„æ¦‚ç‡äº§ç”Ÿé¢å¤–è½¬åŒ–
            # éšæœºé€‰æ‹©ä¸€ä¸ªå•†å“
            random_product = behaviors_df['product_id'].sample(1).iloc[0]
            additional_conversions.append({
                'user_id': user_id,
                'product_id': random_product,
                'behavior_type': 'pay',
                'behavior_time': datetime.now(),
                'session_id': f'S{np.random.randint(100000, 999999)}',
                'device_type': np.random.choice(['mobile', 'desktop', 'tablet']),
                'test_group': 'B'
            })
    
    if additional_conversions:
        additional_df = pd.DataFrame(additional_conversions)
        test_behaviors = pd.concat([test_behaviors, additional_df], ignore_index=True)
        print(f"ä¸ºBç»„å¢åŠ äº† {len(additional_conversions)} ä¸ªé¢å¤–è½¬åŒ–")

#%% å®éªŒç»“æœåˆ†æ
print("\nğŸ“ˆ å®éªŒç»“æœåˆ†æ")
print("-" * 30)

if test_ready and len(test_behaviors) > 0:
    # æŒ‰ç»„è®¡ç®—è½¬åŒ–æŒ‡æ ‡
    print("ã€è½¬åŒ–ç‡åˆ†æã€‘")
    
    # è®¡ç®—å„ç»„çš„è½¬åŒ–ç‡
    group_conversions = test_behaviors[test_behaviors['behavior_type'] == 'pay'].groupby('test_group')['user_id'].nunique()
    group_total_users = test_behaviors.groupby('test_group')['user_id'].nunique()
    
    conversion_rates = {}
    for group in ['A', 'B']:
        conversions = group_conversions.get(group, 0)
        total = group_total_users.get(group, 0)
        rate = conversions / total if total > 0 else 0
        conversion_rates[group] = {
            'conversions': conversions,
            'total_users': total,
            'conversion_rate': rate
        }
        
        print(f"ç»„ {group}:")
        print(f"  æ€»ç”¨æˆ·æ•°: {total:,}")
        print(f"  è½¬åŒ–ç”¨æˆ·æ•°: {conversions:,}")
        print(f"  è½¬åŒ–ç‡: {rate:.2%}")
    
    # è®¡ç®—æå‡å¹…åº¦
    if conversion_rates['A']['conversion_rate'] > 0:
        relative_lift = (conversion_rates['B']['conversion_rate'] - conversion_rates['A']['conversion_rate']) / conversion_rates['A']['conversion_rate']
        absolute_lift = conversion_rates['B']['conversion_rate'] - conversion_rates['A']['conversion_rate']
        
        print(f"\nã€æ•ˆæœè¯„ä¼°ã€‘")
        print(f"ç»å¯¹æå‡: {absolute_lift:.2%}")
        print(f"ç›¸å¯¹æå‡: {relative_lift:.1%}")

#%% ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
print("\nğŸ”¬ ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ")
print("-" * 30)

if test_ready and len(test_behaviors) > 0:
    # è½¬åŒ–ç‡çš„å¡æ–¹æ£€éªŒ
    print("ã€è½¬åŒ–ç‡æ˜¾è‘—æ€§æ£€éªŒ (å¡æ–¹æ£€éªŒ)ã€‘")
    
    # æ„å»ºåˆ—è”è¡¨
    contingency_table = np.array([
        [conversion_rates['A']['conversions'], conversion_rates['A']['total_users'] - conversion_rates['A']['conversions']],
        [conversion_rates['B']['conversions'], conversion_rates['B']['total_users'] - conversion_rates['B']['conversions']]
    ])
    
    # æ‰§è¡Œå¡æ–¹æ£€éªŒ
    chi2, p_value_chi2, dof, expected = chi2_contingency(contingency_table)
    
    print(f"å¡æ–¹ç»Ÿè®¡é‡: {chi2:.4f}")
    print(f"på€¼: {p_value_chi2:.4f}")
    print(f"æ˜¾è‘—æ€§: {'æ˜¯' if p_value_chi2 < 0.05 else 'å¦'} (Î±=0.05)")
    
    # å¦‚æœæœ‰è®¢å•æ•°æ®ï¼Œè¿›è¡Œè®¢å•é‡‘é¢çš„tæ£€éªŒ
    if len(test_orders) > 0:
        print(f"\nã€å¹³å‡è®¢å•é‡‘é¢æ£€éªŒ (tæ£€éªŒ)ã€‘")
        
        group_a_orders = test_orders[test_orders['test_group'] == 'A']['total_amount']
        group_b_orders = test_orders[test_orders['test_group'] == 'B']['total_amount']
        
        if len(group_a_orders) > 0 and len(group_b_orders) > 0:
            # æ‰§è¡Œç‹¬ç«‹æ ·æœ¬tæ£€éªŒ
            t_stat, p_value_t = ttest_ind(group_a_orders, group_b_orders)
            
            print(f"Aç»„å¹³å‡è®¢å•é‡‘é¢: {group_a_orders.mean():.2f}å…ƒ (n={len(group_a_orders)})")
            print(f"Bç»„å¹³å‡è®¢å•é‡‘é¢: {group_b_orders.mean():.2f}å…ƒ (n={len(group_b_orders)})")
            print(f"tç»Ÿè®¡é‡: {t_stat:.4f}")
            print(f"på€¼: {p_value_t:.4f}")
            print(f"æ˜¾è‘—æ€§: {'æ˜¯' if p_value_t < 0.05 else 'å¦'} (Î±=0.05)")
            
            # è®¡ç®—æ•ˆåº”é‡ (Cohen's d)
            pooled_std = np.sqrt(((len(group_a_orders) - 1) * group_a_orders.var() + 
                                 (len(group_b_orders) - 1) * group_b_orders.var()) / 
                                (len(group_a_orders) + len(group_b_orders) - 2))
            cohens_d = (group_b_orders.mean() - group_a_orders.mean()) / pooled_std
            print(f"æ•ˆåº”é‡ (Cohen's d): {cohens_d:.4f}")

#%% ç½®ä¿¡åŒºé—´è®¡ç®—
print("\nğŸ“Š ç½®ä¿¡åŒºé—´è®¡ç®—")
print("-" * 30)

if test_ready and len(test_behaviors) > 0:
    def calculate_conversion_ci(conversions, total, confidence=0.95):
        """è®¡ç®—è½¬åŒ–ç‡çš„ç½®ä¿¡åŒºé—´"""
        if total == 0:
            return 0, 0
        
        p = conversions / total
        z = norm.ppf(1 - (1 - confidence) / 2)
        margin_error = z * np.sqrt(p * (1 - p) / total)
        
        ci_lower = max(0, p - margin_error)
        ci_upper = min(1, p + margin_error)
        
        return ci_lower, ci_upper
    
    print("ã€è½¬åŒ–ç‡95%ç½®ä¿¡åŒºé—´ã€‘")
    for group in ['A', 'B']:
        rate = conversion_rates[group]['conversion_rate']
        conversions = conversion_rates[group]['conversions']
        total = conversion_rates[group]['total_users']
        
        ci_lower, ci_upper = calculate_conversion_ci(conversions, total)
        
        print(f"ç»„ {group}: {rate:.2%} [{ci_lower:.2%}, {ci_upper:.2%}]")
    
    # è®¡ç®—æå‡çš„ç½®ä¿¡åŒºé—´
    if conversion_rates['A']['conversion_rate'] > 0 and conversion_rates['B']['conversion_rate'] > 0:
        print(f"\nã€ç›¸å¯¹æå‡95%ç½®ä¿¡åŒºé—´ã€‘")
        
        # ä½¿ç”¨Deltaæ–¹æ³•è¿‘ä¼¼è®¡ç®—ç›¸å¯¹æå‡çš„ç½®ä¿¡åŒºé—´
        p_a = conversion_rates['A']['conversion_rate']
        p_b = conversion_rates['B']['conversion_rate']
        n_a = conversion_rates['A']['total_users']
        n_b = conversion_rates['B']['total_users']
        
        # ç›¸å¯¹æå‡çš„æ ‡å‡†è¯¯
        relative_lift = (p_b - p_a) / p_a
        se_relative = np.sqrt((p_b * (1 - p_b) / n_b) / p_a**2 + (p_a * (1 - p_a) / n_a * p_b**2) / p_a**4)
        
        z = norm.ppf(0.975)
        ci_lower_rel = relative_lift - z * se_relative
        ci_upper_rel = relative_lift + z * se_relative
        
        print(f"ç›¸å¯¹æå‡: {relative_lift:.1%} [{ci_lower_rel:.1%}, {ci_upper_rel:.1%}]")

#%% é«˜çº§åˆ†æï¼šåˆ†å±‚åˆ†æ
print("\nğŸ” åˆ†å±‚åˆ†æ")
print("-" * 30)

if test_ready and len(test_behaviors) > 0:
    print("ã€æŒ‰ç”¨æˆ·ç‰¹å¾åˆ†å±‚åˆ†æã€‘")
    
    # æŒ‰æ€§åˆ«åˆ†å±‚
    print("\næŒ‰æ€§åˆ«åˆ†å±‚:")
    for gender in ['M', 'F']:
        gender_users = new_users[new_users['gender'] == gender]
        if len(gender_users) > 10:  # ç¡®ä¿æ ·æœ¬é‡è¶³å¤Ÿ
            gender_behaviors = test_behaviors[test_behaviors['user_id'].isin(gender_users['user_id'])]
            
            # è®¡ç®—å„ç»„è½¬åŒ–ç‡
            gender_conversions = gender_behaviors[gender_behaviors['behavior_type'] == 'pay'].groupby('test_group')['user_id'].nunique()
            gender_totals = gender_behaviors.groupby('test_group')['user_id'].nunique()
            
            print(f"  {gender}æ€§ç”¨æˆ·:")
            for group in ['A', 'B']:
                conversions = gender_conversions.get(group, 0)
                total = gender_totals.get(group, 0)
                rate = conversions / total if total > 0 else 0
                print(f"    ç»„{group}: {rate:.2%} ({conversions}/{total})")
    
    # æŒ‰å¹´é¾„åˆ†å±‚
    print("\næŒ‰å¹´é¾„åˆ†å±‚:")
    new_users['age_group'] = pd.cut(new_users['age'], bins=[0, 25, 35, 45, 100], labels=['â‰¤25', '26-35', '36-45', '>45'])
    
    for age_group in new_users['age_group'].cat.categories:
        age_users = new_users[new_users['age_group'] == age_group]
        if len(age_users) > 10:
            age_behaviors = test_behaviors[test_behaviors['user_id'].isin(age_users['user_id'])]
            
            age_conversions = age_behaviors[age_behaviors['behavior_type'] == 'pay'].groupby('test_group')['user_id'].nunique()
            age_totals = age_behaviors.groupby('test_group')['user_id'].nunique()
            
            print(f"  {age_group}å²ç”¨æˆ·:")
            for group in ['A', 'B']:
                conversions = age_conversions.get(group, 0)
                total = age_totals.get(group, 0)
                rate = conversions / total if total > 0 else 0
                print(f"    ç»„{group}: {rate:.2%} ({conversions}/{total})")

#%% å®éªŒæŒç»­æ—¶é—´å’Œç»Ÿè®¡åŠŸæ•ˆåˆ†æ
print("\nâ±ï¸ å®éªŒæŒç»­æ—¶é—´å’Œç»Ÿè®¡åŠŸæ•ˆåˆ†æ")
print("-" * 30)

if test_ready:
    def calculate_test_duration(daily_users, required_sample_size):
        """è®¡ç®—å®éªŒæ‰€éœ€æŒç»­æ—¶é—´"""
        return required_sample_size / daily_users
    
    # ä¼°ç®—æ¯æ—¥æ–°ç”¨æˆ·æ•°
    recent_users = users_df[users_df['register_date'] >= cutoff_date]
    days_in_period = (recent_date - cutoff_date).days
    daily_new_users = len(recent_users) / days_in_period if days_in_period > 0 else 1
    
    print(f"ã€å®éªŒæŒç»­æ—¶é—´ä¼°ç®—ã€‘")
    print(f"æœ€è¿‘30å¤©æ—¥å‡æ–°ç”¨æˆ·: {daily_new_users:.1f} äºº")
    
    # è®¡ç®—ä¸åŒæ•ˆåº”é‡ä¸‹çš„å®éªŒæŒç»­æ—¶é—´
    for mde in [0.10, 0.15, 0.20]:
        required_sample = calculate_sample_size(baseline_conversion_rate, mde)
        duration_days = calculate_test_duration(daily_new_users, required_sample)
        print(f"æ£€æµ‹ {mde:.0%} æå‡éœ€è¦: {duration_days:.0f} å¤© (æ¯ç»„ {required_sample:,} ç”¨æˆ·)")
    
    # ç»Ÿè®¡åŠŸæ•ˆåˆ†æ
    print(f"\nã€å½“å‰å®éªŒçš„ç»Ÿè®¡åŠŸæ•ˆã€‘")
    current_sample_per_group = len(new_users) // 2
    
    def calculate_power(n, baseline_rate, effect_size, alpha=0.05):
        """è®¡ç®—ç»Ÿè®¡åŠŸæ•ˆ"""
        p1 = baseline_rate
        p2 = baseline_rate * (1 + effect_size)
        
        # è®¡ç®—æ ‡å‡†åŒ–æ•ˆåº”é‡
        pooled_p = (p1 + p2) / 2
        se = np.sqrt(2 * pooled_p * (1 - pooled_p) / n)
        z_alpha = norm.ppf(1 - alpha/2)
        z_beta = (abs(p2 - p1) - z_alpha * se) / se
        
        power = norm.cdf(z_beta)
        return power
    
    for effect in [0.10, 0.15, 0.20]:
        power = calculate_power(current_sample_per_group, baseline_conversion_rate, effect)
        print(f"æ£€æµ‹ {effect:.0%} æ•ˆåº”çš„åŠŸæ•ˆ: {power:.1%}")

#%% ä¸šåŠ¡å»ºè®®å’Œåç»­è¡ŒåŠ¨
print("\nğŸ’¼ ä¸šåŠ¡å»ºè®®å’Œåç»­è¡ŒåŠ¨")
print("-" * 30)

if test_ready:
    print("ã€å®éªŒç»“æœæ€»ç»“ã€‘")
    
    if 'relative_lift' in locals() and 'p_value_chi2' in locals():
        # åŸºäºå®é™…ç»“æœçš„å»ºè®®
        is_significant = p_value_chi2 < 0.05
        is_meaningful = abs(relative_lift) > 0.05  # 5%ä»¥ä¸Šçš„ç›¸å¯¹æ”¹å˜è®¤ä¸ºæœ‰ä¸šåŠ¡æ„ä¹‰
        
        print(f"ç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¾è‘—' if is_significant else 'ä¸æ˜¾è‘—'}")
        print(f"ä¸šåŠ¡æ„ä¹‰: {'æœ‰æ„ä¹‰' if is_meaningful else 'æ„ä¹‰ä¸å¤§'}")
        
        if is_significant and is_meaningful:
            if relative_lift > 0:
                print(f"\nâœ… å»ºè®®å…¨é‡æ¨å¹¿ä¼˜æƒ åˆ¸ç­–ç•¥")
                print(f"é¢„æœŸæ”¶ç›Š: è½¬åŒ–ç‡æå‡ {relative_lift:.1%}")
            else:
                print(f"\nâŒ å»ºè®®åœæ­¢ä¼˜æƒ åˆ¸ç­–ç•¥")
                print(f"è´Ÿé¢å½±å“: è½¬åŒ–ç‡ä¸‹é™ {abs(relative_lift):.1%}")
        else:
            print(f"\nâš ï¸ å»ºè®®ç»§ç»­è§‚å¯Ÿæˆ–é‡æ–°è®¾è®¡å®éªŒ")
            if not is_significant:
                print("- å½“å‰ç»“æœä¸å…·ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´æˆ–æ›´å¤§æ ·æœ¬é‡")
            if not is_meaningful:
                print("- æ•ˆæœé‡è¾ƒå°ï¼Œè€ƒè™‘è°ƒæ•´ä¼˜æƒ åˆ¸é¢é¢æˆ–ç­–ç•¥")
    
    print(f"\nã€åç»­è¡ŒåŠ¨è®¡åˆ’ã€‘")
    print("1. ç›‘æ§å…³é”®æŒ‡æ ‡å˜åŒ–è¶‹åŠ¿")
    print("2. åˆ†æç”¨æˆ·ç•™å­˜å’Œå¤è´­è¡Œä¸º")
    print("3. è¯„ä¼°ä¼˜æƒ åˆ¸æˆæœ¬æ•ˆç›Š")
    print("4. è€ƒè™‘ä¸ªæ€§åŒ–ä¼˜æƒ åˆ¸ç­–ç•¥")
    print("5. è®¾è®¡é•¿æœŸæ•ˆæœè·Ÿè¸ªæœºåˆ¶")
    
    # é£é™©è¯„ä¼°
    print(f"\nã€é£é™©è¯„ä¼°ã€‘")
    print("â€¢ æ ·æœ¬åå·®: ä»…é’ˆå¯¹æ–°ç”¨æˆ·ï¼Œç»“æœå¯èƒ½ä¸é€‚ç”¨äºè€ç”¨æˆ·")
    print("â€¢ æ—¶é—´åå·®: å®éªŒæœŸé—´å¯èƒ½å—å­£èŠ‚æ€§ç­‰å› ç´ å½±å“")
    print("â€¢ éœæ¡‘æ•ˆåº”: ç”¨æˆ·å¯èƒ½å› çŸ¥é“å‚ä¸å®éªŒè€Œæ”¹å˜è¡Œä¸º")
    print("â€¢ é•¿æœŸæ•ˆåº”: çŸ­æœŸå®éªŒå¯èƒ½æ— æ³•åæ˜ é•¿æœŸå½±å“")

#%% ä¿å­˜å®éªŒç»“æœ
print("\nğŸ’¾ ä¿å­˜å®éªŒç»“æœ")
print("-" * 30)

if test_ready:
    # åˆ›å»ºå®éªŒæŠ¥å‘Š
    experiment_report = {
        'experiment_name': 'æ–°ç”¨æˆ·ä¼˜æƒ åˆ¸A/Bæµ‹è¯•',
        'start_date': datetime.now().strftime('%Y-%m-%d'),
        'test_groups': {
            'A': 'æ§åˆ¶ç»„ï¼ˆæ— ä¼˜æƒ åˆ¸ï¼‰',
            'B': 'å®éªŒç»„ï¼ˆ10å…ƒä¼˜æƒ åˆ¸ï¼‰'
        },
        'sample_sizes': {
            'A': int(conversion_rates.get('A', {}).get('total_users', 0)),
            'B': int(conversion_rates.get('B', {}).get('total_users', 0))
        },
        'conversion_rates': {
            'A': float(conversion_rates.get('A', {}).get('conversion_rate', 0)),
            'B': float(conversion_rates.get('B', {}).get('conversion_rate', 0))
        },
        'statistical_significance': bool(p_value_chi2 < 0.05) if 'p_value_chi2' in locals() else None,
        'p_value': float(p_value_chi2) if 'p_value_chi2' in locals() else None,
        'relative_lift': float(relative_lift) if 'relative_lift' in locals() else None,
        'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # ä¿å­˜å®éªŒæŠ¥å‘Š
    import json
    os.makedirs('data/processed', exist_ok=True)
    with open('data/processed/ab_test_report.json', 'w', encoding='utf-8') as f:
        json.dump(experiment_report, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    if 'new_users' in locals():
        new_users.to_csv('data/processed/ab_test_users.csv', index=False)
    
    print("âœ… A/Bæµ‹è¯•åˆ†æå®Œæˆï¼")
    print("\nğŸ“‹ å®éªŒæ€»ç»“:")
    print(f"  - æµ‹è¯•ç”¨æˆ·: {len(new_users) if 'new_users' in locals() else 0:,} äºº")
    if 'conversion_rates' in locals():
        print(f"  - Aç»„è½¬åŒ–ç‡: {conversion_rates.get('A', {}).get('conversion_rate', 0):.2%}")
        print(f"  - Bç»„è½¬åŒ–ç‡: {conversion_rates.get('B', {}).get('conversion_rate', 0):.2%}")
    if 'relative_lift' in locals():
        print(f"  - ç›¸å¯¹æå‡: {relative_lift:.1%}")
    if 'p_value_chi2' in locals():
        print(f"  - ç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¾è‘—' if p_value_chi2 < 0.05 else 'ä¸æ˜¾è‘—'} (p={p_value_chi2:.4f})")
    print(f"  - å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ° data/processed/ ç›®å½•")

#%% å®éªŒå­¦ä¹ å’Œæ”¹è¿›
print("\nğŸ“ å®éªŒå­¦ä¹ å’Œæ”¹è¿›")
print("-" * 30)

print("ã€æœ¬æ¬¡å®éªŒçš„å­¦ä¹ è¦ç‚¹ã€‘")
print("1. æ ·æœ¬é‡è®¡ç®—çš„é‡è¦æ€§ - ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç»Ÿè®¡åŠŸæ•ˆ")
print("2. åˆ†ç»„å¹³è¡¡æ€§æ£€æŸ¥ - é¿å…æ··æ·†å˜é‡å½±å“ç»“æœ")
print("3. å¤šé‡æŒ‡æ ‡åˆ†æ - ä¸ä»…çœ‹è½¬åŒ–ç‡ï¼Œè¿˜è¦çœ‹è®¢å•é‡‘é¢ç­‰")
print("4. åˆ†å±‚åˆ†æä»·å€¼ - ä¸åŒç”¨æˆ·ç¾¤ä½“å¯èƒ½æœ‰ä¸åŒååº”")
print("5. ç½®ä¿¡åŒºé—´è§£è¯» - ç‚¹ä¼°è®¡è¦ç»“åˆåŒºé—´ä¼°è®¡çœ‹")

print(f"\nã€æ”¹è¿›å»ºè®®ã€‘")
print("â€¢ å¢åŠ æ›´å¤šä¸šåŠ¡æŒ‡æ ‡ï¼šç”¨æˆ·ç•™å­˜ã€LTVã€æ»¡æ„åº¦ç­‰")
print("â€¢ è€ƒè™‘å¤šå˜é‡æµ‹è¯•ï¼šåŒæ—¶æµ‹è¯•ä¼˜æƒ åˆ¸é¢é¢ã€æ–‡æ¡ˆç­‰")
print("â€¢ å®æ–½åºè´¯åˆ†æï¼šåŠ¨æ€è°ƒæ•´å®éªŒæŒç»­æ—¶é—´")
print("â€¢ å»ºç«‹å®éªŒå¹³å°ï¼šæ ‡å‡†åŒ–A/Bæµ‹è¯•æµç¨‹")
print("â€¢ é•¿æœŸè·Ÿè¸ªæœºåˆ¶ï¼šè¯„ä¼°å®éªŒçš„é•¿æœŸä¸šåŠ¡å½±å“")

print(f"\n{'='*50}")
print("ğŸ§ª A/Bæµ‹è¯•åˆ†æå®Œæˆï¼")
print("ğŸ‰ ç”µå•†ç”¨æˆ·è¡Œä¸ºåˆ†æé¡¹ç›®å…¨éƒ¨å®Œæˆï¼")
print("\nğŸ“Š é¡¹ç›®æˆæœ:")
print("  âœ… æ•°æ®æ¢ç´¢å’Œè´¨é‡è¯„ä¼°")
print("  âœ… ç”¨æˆ·è¡Œä¸ºæ·±åº¦åˆ†æ")
print("  âœ… RFMç”¨æˆ·ä»·å€¼åˆ†æ") 
print("  âœ… è½¬åŒ–æ¼æ–—åˆ†æ")
print("  âœ… A/Bæµ‹è¯•è®¾è®¡å’Œåˆ†æ")
print("  âœ… ä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®")
print("\nğŸš€ æ­å–œæ‚¨å®Œæˆäº†ä¸€ä¸ªå®Œæ•´çš„æ•°æ®åˆ†æé¡¹ç›®ï¼") 
# %%
